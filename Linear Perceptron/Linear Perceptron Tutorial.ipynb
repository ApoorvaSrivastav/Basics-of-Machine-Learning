{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aNOlBglREJwz"
   },
   "source": [
    "Run the below cell to import all relevant notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2874,
     "status": "ok",
     "timestamp": 1596983910402,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "05nyKS2TBZJC",
    "outputId": "fdd07951-2d3f-484a-a790-d6e08331baa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running importer\n"
     ]
    }
   ],
   "source": [
    "import io, os, sys, types\n",
    "from IPython import get_ipython\n",
    "from nbformat import read\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "def find_notebook(fullname, path=None):\n",
    "    \"\"\"find a notebook, given its fully qualified name and an optional path\n",
    "\n",
    "    This turns \"foo.bar\" into \"foo/bar.ipynb\"\n",
    "    and tries turning \"Foo_Bar\" into \"Foo Bar\" if Foo_Bar\n",
    "    does not exist.\n",
    "    \"\"\"\n",
    "    name = fullname.rsplit('.', 1)[-1]\n",
    "    if not path:\n",
    "        path = ['']\n",
    "    for d in path:\n",
    "        nb_path = os.path.join(d, name + \".ipynb\")\n",
    "        #print('searching: %s'%nb_path)\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "        # let import Notebook_Name find \"Notebook Name.ipynb\"\n",
    "        nb_path = nb_path.replace(\"_\", \" \")\n",
    "        #print('searching: %s' % nb_path)\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "\n",
    "class NotebookLoader(object):\n",
    "    \"\"\"Module Loader for Jupyter Notebooks\"\"\"\n",
    "    def __init__(self, path=None):\n",
    "        self.shell = InteractiveShell.instance()\n",
    "        self.path = path\n",
    "\n",
    "    def load_module(self, fullname):\n",
    "        \"\"\"import a notebook as a module\"\"\"\n",
    "        path = find_notebook(fullname, self.path)\n",
    "\n",
    "        print (\"importing Jupyter notebook from %s\" % path)\n",
    "\n",
    "        # load the notebook object\n",
    "        with io.open(path, 'r', encoding='utf-8') as f:\n",
    "            nb = read(f, 4)\n",
    "\n",
    "\n",
    "        # create the module and add it to sys.modules\n",
    "        # if name in sys.modules:\n",
    "        #    return sys.modules[name]\n",
    "        mod = types.ModuleType(fullname)\n",
    "        mod.__file__ = path\n",
    "        mod.__loader__ = self\n",
    "        mod.__dict__['get_ipython'] = get_ipython\n",
    "        sys.modules[fullname] = mod\n",
    "\n",
    "        # extra work to ensure that magics that would affect the user_ns\n",
    "        # actually affect the notebook module's ns\n",
    "        save_user_ns = self.shell.user_ns\n",
    "        self.shell.user_ns = mod.__dict__\n",
    "\n",
    "        #print('Found %d cells'%len(nb.cells))\n",
    "        try:\n",
    "          for cell in nb.cells:\n",
    "            if cell.cell_type == 'code':\n",
    "                # transform the input to executable Python\n",
    "                code = self.shell.input_transformer_manager.transform_cell(cell.source)\n",
    "                # run the code in themodule\n",
    "                exec(code, mod.__dict__)\n",
    "        finally:\n",
    "            self.shell.user_ns = save_user_ns\n",
    "        return mod\n",
    "\n",
    "class NotebookFinder(object):\n",
    "    \"\"\"Module finder that locates Jupyter Notebooks\"\"\"\n",
    "    def __init__(self):\n",
    "        self.loaders = {}\n",
    "\n",
    "    def find_module(self, fullname, path=None):\n",
    "        nb_path = find_notebook(fullname, path)\n",
    "        if not nb_path:\n",
    "            return\n",
    "\n",
    "        key = path\n",
    "        if path:\n",
    "            # lists aren't hashable\n",
    "            key = os.path.sep.join(path)\n",
    "\n",
    "        if key not in self.loaders:\n",
    "            self.loaders[key] = NotebookLoader(path)\n",
    "        return self.loaders[key]\n",
    "\n",
    "\n",
    "#  register the NotebookFinder with sys.meta_path\n",
    "print('running importer')\n",
    "sys.meta_path.append(NotebookFinder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 322
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12278,
     "status": "ok",
     "timestamp": 1596983919850,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "yxJIArYx93fy",
    "outputId": "5a261679-61d2-4755-c5ee-2c09742c39ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: gif in c:\\users\\asus\\anaconda3\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied, skipping upgrade: Pillow>=7.1.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from gif) (7.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.0.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Asus\\Anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install -U gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14073,
     "status": "ok",
     "timestamp": 1596983921673,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "OmcZvOJHJ0Qp",
    "outputId": "30aedb40-abdf-4f3b-efba-20dc33fbd835"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f6ace42ba09b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_classification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_decision_boundary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_class_signum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "# Import all relevant functions\n",
    "from sklearn import datasets\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import utils\n",
    "\n",
    "from utils import plot_decision_boundary, multi_class_signum, get_accuracy, get_prediction\n",
    "from utils import plot_2D_input_datapoints, generate_gifs, normalize, signum\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import math\n",
    "import gif\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BIO1nums-lFw"
   },
   "source": [
    "# Introduction to Perceptron Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V-4xvt_B_OHB"
   },
   "source": [
    "The Perceptron Algorithm is a supervised learning algorithm of binary classifiers. A binary classifier is a function that decides whether an input data vector belongs to a specific class. In our case, we define our output class $\\mathbf{y} = \\{-1, +1\\}$, where $+1$ denotes positive class and $-1$ denotes negative class.\n",
    "\n",
    "Perceptron algorithm makes a fundamental assumption i.e., all datapoints are linearly separable.\n",
    "\n",
    "In our perceptron algorithm problem, our goal is to classify a set of points into two classes in n-dimensional space. This classification is done by a hyperplane defined by a hypothesis function, $h_{\\mathbf{w}}$ as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{X}: \\mathbf{w^{\\top}X + b} = 0\n",
    "\\end{equation}\n",
    "\n",
    "where,\n",
    "*   $\\mathbf{m}  $ Number of examples/datapoints.\n",
    "*   $\\mathbf{d}  $ Number of features/dimensions.\n",
    "*   $\\mathbf{n}  $ Number of output categories.\n",
    "*   $\\mathbf{X} \\in \\mathbf{R^{m \\times d}}$\n",
    "*   $\\mathbf{w} \\in \\mathbf{R^{d \\times n}}$, Weights of the hyperplane\n",
    "*   $\\mathbf{b} \\in \\mathbf{R^n} $, Bias of the hyperplane\n",
    "\n",
    "Instead of finding both $\\mathbf{w}$ and $\\mathbf{b}$, we make the following modifications to the above equation:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{x_i} \\rightarrow\n",
    "\\begin{bmatrix}\n",
    "\\mathbf{x_i} \\\\ 1\n",
    "\\end{bmatrix},\n",
    "\\mathbf{w} \\rightarrow\n",
    "\\begin{bmatrix}\n",
    "\\mathbf{w} \\\\ \\mathbf{b}\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "When we generalize this modification for $\\mathbf{X}$, our hyperplane necessarily goes through origin, which simplifies our hypothesis function as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "h_{\\mathbf{w}} = \\mathbf{w^{\\top} X}\n",
    "\\end{equation}\n",
    "\n",
    "Depending on the sign of this hypothesis function, it can predict three situations,\n",
    "\n",
    "\\begin{equation}\n",
    "sign(h_{\\mathbf{w}}) = sign(\\mathbf{w^{\\top} X}) = \\left\\{\n",
    "  \\begin{array}{ll}\n",
    "    \\text{1 if } \\; \\mathbf{w^{\\top} X} \\text{ > 0}\\\\\n",
    "    \\text{-1 if } \\; \\mathbf{w^{\\top} X} \\text{ <= 0}\n",
    "  \\end{array}\n",
    "  \\right.\n",
    "\\end{equation}\n",
    "\n",
    "In our binary classification problem, the hypothesis function, $h_{\\mathbf{w}}$, classifies a particular datapoint $(x_i, y_i)$ correctly if,\n",
    "\n",
    "\\begin{equation}\n",
    "sign(\\mathbf{w^{\\top}x_i}) = \\mathbf{y_i} \\equiv \\mathbf{y_i \\cdot w^{\\top} x_i > 0}\n",
    "\\end{equation}\n",
    "\n",
    "On the other hand, $h_{\\mathbf{w}}$ incorrectly classifies a datapoint $(x_i, y_i)$ if,\n",
    "\n",
    "\\begin{equation}\n",
    "sign(\\mathbf{w^{\\top}x_i}) \\neq \\mathbf{y_i} \\equiv \\mathbf{y_i \\cdot w^{\\top} x_i \\leq 0}\n",
    "\\end{equation}\n",
    "\n",
    "$\\;$\n",
    "\n",
    "<img class=\"align-center\" border=\"2\" src=\"https://www.cs.cornell.edu/courses/cs4780/2017sp/lectures/images/perceptron/perceptron_img1.png\" width=\"500\"/>\n",
    "\n",
    "$\\;$\n",
    "\n",
    "The quantity, $\\mathbf{y \\cdot w^{\\top} X}$, is the margin or the distance between the datapoints in $\\mathbf{X}$ and the hyperplane.\n",
    "\n",
    "Consider our desired behavior: we would like to have $\\mathbf{y \\cdot w^{\\top} X > 0}$ for all training examples, and penalize those $\\mathbf{w}$ where $\\mathbf{y \\cdot w^{\\top} X \\leq 0}$.\n",
    "\n",
    "Intuitively, we would like to have our loss function defined only for misclassified training datapoints. For the correctly classified ones, we define zero loss.\n",
    "\n",
    "Hence, our loss function is as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "J = \\sum_{x_i \\in \\varepsilon} - \\mathbf{y_i \\cdot w^{\\top} x_i}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\varepsilon$ is the set of misclassified samples i.e.,\n",
    "\n",
    "\\begin{equation}\n",
    "\\varepsilon = \\{\\mathbf{x_i | w^{\\top} x_i < 0 }\\}\n",
    "\\end{equation}\n",
    "\n",
    "This loss is differentiable. For a batch of samples, we can now write our gradient descent update rule as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{w^{k+1} \\leftarrow w^k} + \\eta \\sum_{x_i \\in \\varepsilon} \\mathbf{y_i x_i}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pnQpjXa3DgR9"
   },
   "source": [
    "Now that we have seen an introduction on how the Perceptron model works, we will dive into the code implementations. Also, we will answer some open-ended questions such as:\n",
    "\n",
    "1.   Effect of weight initialization\n",
    "2.   Do we need biases?\n",
    "3.   What happens if we have non-linearly separable dataset, like XOR problem?\n",
    "4.   Training perceptron model on a partially separable dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GN5FSt66RLjd"
   },
   "source": [
    "# Example 1 - Toy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14067,
     "status": "ok",
     "timestamp": 1596983921677,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "RDTaWuuvTviP"
   },
   "outputs": [],
   "source": [
    "# Setting the seed to ensure reproducibility of experiments\n",
    "np.random.seed(10)\n",
    "\n",
    "# Getting only linearly separable dataset\n",
    "separable = False\n",
    "while not separable:\n",
    "  samples = make_classification(n_samples=1000, n_features=2, n_redundant=0, n_informative=1, n_clusters_per_class=1, flip_y=-1)\n",
    "  red = samples[0][samples[1] == 0]\n",
    "  blue = samples[0][samples[1] == 1]\n",
    "  separable = any([red[:, k].max() < blue[:, k].min() or red[:, k].min() > blue[:, k].max() for k in range(2)])\n",
    "\n",
    "X, y = samples\n",
    "\n",
    "# Adding column of ones to absorb bias b of the hyperplane into X\n",
    "bias_ones = np.ones((len(X), 1))\n",
    "X = np.hstack((X, bias_ones))\n",
    "\n",
    "# Setting y from {0,1} to {-1, 1}\n",
    "y[y == 0] = -1\n",
    "y = y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14048,
     "status": "ok",
     "timestamp": 1596983921689,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "9n5iS1TNFrP9",
    "outputId": "878adb09-7d6f-45f1-f698-f20e1fbfde5e"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'seaborn' has no attribute 'regplot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-a6a1e8affd2e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_2D_input_datapoints\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\SMAI\\HW\\HW Set7\\utils.ipynb\u001b[0m in \u001b[0;36mplot_2D_input_datapoints\u001b[1;34m(X_inp, y_inp)\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'seaborn' has no attribute 'regplot'"
     ]
    }
   ],
   "source": [
    "plot_2D_input_datapoints(X[:, :2], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14015,
     "status": "ok",
     "timestamp": 1596983921692,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "u5rrR7CJnpoa",
    "outputId": "d978ceb0-2ae2-466b-a804-4cd1fded406e"
   },
   "outputs": [],
   "source": [
    "# Train-Val-Test split\n",
    "X_train_val, X_test, Y_train_val, Y_test = train_test_split(X, y, shuffle=True, test_size = 0.2)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train_val, Y_train_val, test_size = 0.125)\n",
    "\n",
    "print(\"Training dataset: \", X_train.shape)\n",
    "print(\"Validation dataset: \", X_val.shape)\n",
    "print(\"Test dataset: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14004,
     "status": "ok",
     "timestamp": 1596983921694,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "F4HJx37iG3nn"
   },
   "outputs": [],
   "source": [
    "# Normalizing X_train and absorbing weight b of the hyperplane\n",
    "X_normalized_train = normalize(X_train[:, :2])\n",
    "\n",
    "b_ones = np.ones((len(X_normalized_train), 1))\n",
    "X_normalized_train = np.hstack((X_normalized_train, b_ones))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ye-6RDBF_tL"
   },
   "source": [
    "Note above that 1st and 2nd column are input data features and the 3rd column effectively translates to the bias column. Adding column of ones to the input data helps in easier matrix multiplication between the input data $X$ and weights $w$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-bgqqnr3hTy4"
   },
   "source": [
    "The pseudo-code for our perceptron algorithm is as follows:\n",
    "\n",
    "<img class=\"align-center\" border=\"2\" src=\"https://www.cs.cornell.edu/courses/cs4780/2017sp/lectures/images/perceptron/perceptron_algo.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14947,
     "status": "ok",
     "timestamp": 1596983922645,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "A9z-aoNUqXcP"
   },
   "outputs": [],
   "source": [
    "# Perceptron training algorithm\n",
    "def train(X_train, Y_train, weights, learning_rate=1, total_epochs=100):\n",
    "\n",
    "  \"\"\"Training method for Perceptron.\n",
    "  \n",
    "  Parameters\n",
    "  -----------\n",
    "\n",
    "  X_train: ndarray (num_examples(rows) vs num_features(columns))\n",
    "    Input dataset which perceptron will use to learn optimal weights\n",
    "  \n",
    "  Y_train: ndarray (num_examples(rows) vs class_labels(columns))\n",
    "    Class labels for input data\n",
    "\n",
    "  weights: ndarray (num_features vs n_output)\n",
    "    Weights used to train the network and predict on test set\n",
    "\n",
    "  learning_rate: int\n",
    "    Learning rate use to learn and update weights\n",
    "  \n",
    "  total_epochs: int\n",
    "    Max number of epochs to train the perceptron model\n",
    "  \"\"\"\n",
    "\n",
    "  n_samples, _ = np.shape(X_train)\n",
    "  history_weights = []\n",
    "  epoch = 1\n",
    "\n",
    "  # Number of missclassified points we would like to see in the train set.\n",
    "  # While training, its value will change every epoch. If m==0, our training \n",
    "  # error will be zero.\n",
    "  m = 1\n",
    "\n",
    "  # If the most recent weights gave 0 misclassifications, break the loop.\n",
    "  # Else continue until total_epochs is completed.\n",
    "  while m != 0 and epoch <= total_epochs:\n",
    "    m = 0\n",
    "\n",
    "    # Compute weighted inputs and predict class labels on training set.\n",
    "    weights_transpose_x = np.dot(X_train, weights)\n",
    "    weights_transpose_x = signum(weights_transpose_x)\n",
    "    y_train_out = np.multiply(Y_train, weights_transpose_x)\n",
    "    epoch += 1\n",
    "    \n",
    "    # Collecting misclassified indexes and count them\n",
    "    y_miscls_idxs = np.argwhere(y_train_out <= 0)[:, 0]\n",
    "    y_miscls_idxs = np.unique(y_miscls_idxs)\n",
    "    m = len(y_miscls_idxs)\n",
    "\n",
    "    # Calculate gradients and update weights\n",
    "    dweights = np.dot((X_train[y_miscls_idxs]).T, Y_train[y_miscls_idxs])\n",
    "    weights += (learning_rate/n_samples) * dweights\n",
    "    weights = np.round(weights, decimals=4)\n",
    "\n",
    "    # Append weights to visualize decision boundary later\n",
    "    history_weights.append(weights)\n",
    "\n",
    "  if m == 0 and epoch <= total_epochs:\n",
    "    print(\"Training has stabilized with all points classified: \", epoch)\n",
    "  else:\n",
    "    print(f'Training completed at {epoch-1} epochs. {m} misclassified points remain.')\n",
    "\n",
    "  return history_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14939,
     "status": "ok",
     "timestamp": 1596983922649,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "RgaljZ10EjKD"
   },
   "outputs": [],
   "source": [
    "# Initializing weights to zero\n",
    "_, n_features = np.shape(X_normalized_train)\n",
    "_, n_outputs = np.shape(Y_train)\n",
    "\n",
    "weights = np.zeros((n_features, n_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14922,
     "status": "ok",
     "timestamp": 1596983922664,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "C_4Fa59K11rQ",
    "outputId": "21e9b8b4-04bd-4dcf-969b-097ed428a07e"
   },
   "outputs": [],
   "source": [
    "trained_weights = train(X_normalized_train, Y_train, weights, learning_rate=0.05, total_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ueZHrkqMPYze"
   },
   "source": [
    "Visualizing decision boundary for training set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 37329,
     "status": "ok",
     "timestamp": 1596983945103,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "ZK3TEeLd3BZU",
    "outputId": "0e2e441f-030d-4272-975a-71aa4b7d0151"
   },
   "outputs": [],
   "source": [
    "generate_gifs(X_train, Y_train, trained_weights, 'train', path='content/training_decision_boundary.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ETCZSdAXfQO"
   },
   "source": [
    "![perceptron_training_decision_boundary](https://drive.google.com/uc?id=1llryslKm54-7Z2i6z-TykAmNu0CNd0io)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 37297,
     "status": "ok",
     "timestamp": 1596983945105,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "YbYWSS__CzTf",
    "outputId": "20cd8eb6-701e-4cfc-dc28-7bf783656b76"
   },
   "outputs": [],
   "source": [
    "best_weights = trained_weights[-1]\n",
    "train_acc, _ = get_prediction(X_train, Y_train, best_weights, get_acc=True)\n",
    "val_acc, _ = get_prediction(X_val, Y_val, best_weights, get_acc=True)\n",
    "test_acc, _ = get_prediction(X_test, Y_test, best_weights, get_acc=True)\n",
    "\n",
    "print(\"Evaluation results\")\n",
    "print(\"Training accuracy: {:.3f}\" .format(train_acc))\n",
    "print(\"Validation accuracy: {:.3f}\" .format(val_acc))\n",
    "print(\"Test accuracy: {:.3f}\" .format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 593
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 37267,
     "status": "ok",
     "timestamp": 1596983945107,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "k4YWSk3oC80X",
    "outputId": "881725a1-c066-4f7f-d510-0b59ed84bbb8"
   },
   "outputs": [],
   "source": [
    "plot_decision_boundary(X_test, Y_test, best_weights, dataset_type='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZQQfFFOrqST3"
   },
   "source": [
    "## Effect of weight initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OhmkTxneBdQu"
   },
   "source": [
    "Previously, we had initialized our weights to zero. What would have happened if we had initialized our weights too large? Let's check that too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 37256,
     "status": "ok",
     "timestamp": 1596983945108,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "CriuDmQ1BnWV"
   },
   "outputs": [],
   "source": [
    "# Initializing large weights\n",
    "weights = np.ones((n_features, n_outputs)) * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 37218,
     "status": "ok",
     "timestamp": 1596983945109,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "nciXzzHYBpWy",
    "outputId": "3799662c-9e0c-4a2a-ab29-f3103ce80e09"
   },
   "outputs": [],
   "source": [
    "trained_weights = train(X_normalized_train, Y_train, weights, learning_rate=0.05, total_epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4KRPjfvcCCpE"
   },
   "source": [
    "We see a similar effect. After 1000 epochs, training has still not converged. Let's see when does it converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 37981,
     "status": "ok",
     "timestamp": 1596983945890,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "kBA5ef6nCPoZ",
    "outputId": "0cdb92d9-b0a7-41a1-a8ee-cda077b8ce27"
   },
   "outputs": [],
   "source": [
    "trained_weights = train(X_normalized_train, Y_train, weights, learning_rate=0.05, total_epochs=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3LtMpR3BChlB"
   },
   "source": [
    "We shall see about better strategies of weight initializations later in the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1dmloxXD78G3"
   },
   "source": [
    "## Effect of biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MquBGNPEUtSb"
   },
   "source": [
    "Bias are additional constants attached neurons and added to the weighted input before the activation function is applied.\n",
    "\n",
    "Let's visualize this effect of adding and removing biases in perceptron. The characteristics of biases found here is broadly applicable to other neural networks algorithms.\n",
    "\n",
    "We know that an equation of the line can be described as such: $y = w \\times x + b$. From this equation we know that intercept $b$ allows our equation to translate in our 2D plane.\n",
    "\n",
    "W.r.t our perceptron model, we had derived a similar analogy: $Y_{prediction} = \\text{signum_activation}(weights \\times X_{input} + bias$).\n",
    "\n",
    "Let us define an equation of line as follows: $0.25x - 0.85y + 3 = 0$. If we consider this line as our decision boundary, our optimal weights $=[0.25, -0.85]$ and bias $=[3]$. We will generate a random set of points on either side of line but not on it (for simplicity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 37973,
     "status": "ok",
     "timestamp": 1596983945891,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "VMutSunMdqVG"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 37968,
     "status": "ok",
     "timestamp": 1596983945893,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "WFwBBrq4esPQ"
   },
   "outputs": [],
   "source": [
    "# Setting the seed to ensure reproducibility of experiments\n",
    "np.random.seed(10)\n",
    "\n",
    "X = np.random.randint(-10, 10, size=(1000, 2))\n",
    "\n",
    "# Adding column of ones to absorb bias b of the hyperplane into X\n",
    "bias_ones = np.ones((len(X), 1))\n",
    "X = np.hstack((X, bias_ones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 37962,
     "status": "ok",
     "timestamp": 1596983945895,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "mS0AJs1revLF"
   },
   "outputs": [],
   "source": [
    "# our optimal weights\n",
    "best_weights = np.array([[0.25], [-0.85], [3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 37956,
     "status": "ok",
     "timestamp": 1596983945897,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "JVZetUSR8cKr"
   },
   "outputs": [],
   "source": [
    "# Method to generate random set of points on either side of line but not on it.\n",
    "def get_relevant_points(X, weights):\n",
    "  y_pred = np.dot(X, weights)\n",
    "  y_pred[y_pred < 0] = -1\n",
    "  y_pred[y_pred > 0] = 1\n",
    "  relevant_idxs = np.argwhere(y_pred != 0)[:, 0]\n",
    "  on_the_line_idxs = np.argwhere(y_pred == 0)[:, 0]\n",
    "  return y_pred, relevant_idxs, on_the_line_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 37951,
     "status": "ok",
     "timestamp": 1596983945899,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "dGv6oSKDE9Ea"
   },
   "outputs": [],
   "source": [
    "y_pred, relevant_idxs, on_the_line_idxs = get_relevant_points(X, best_weights)\n",
    "\n",
    "X_on_the_line = X[on_the_line_idxs]\n",
    "y_on_the_line = y[on_the_line_idxs]\n",
    "\n",
    "X = X[relevant_idxs]\n",
    "y = y_pred[relevant_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 593
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 39533,
     "status": "ok",
     "timestamp": 1596983947498,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "ZyU0mzkekVvF",
    "outputId": "b09ab49d-6353-43db-9f24-e4b031ba2580"
   },
   "outputs": [],
   "source": [
    "plot_decision_boundary(X, y, best_weights, dataset_type='test', bias='on', class_label_01_form='off', model_type='perceptron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 39507,
     "status": "ok",
     "timestamp": 1596983947501,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "lM20gaNQF0ek",
    "outputId": "c924f536-0860-48eb-e455-12e158970d36"
   },
   "outputs": [],
   "source": [
    "# Removing the column of ones\n",
    "X = X[:, :2]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vFUE-SOtlxis"
   },
   "source": [
    "Note that after generating the samples above, we aren't appending a column of ones in $X$. Hence, when we multiply $X$ with weights $w$, we are not including the bias term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 39501,
     "status": "ok",
     "timestamp": 1596983947502,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "Lyk1hZ0XFEtF"
   },
   "outputs": [],
   "source": [
    "# Initializing weights to zero\n",
    "_, n_features = np.shape(X)\n",
    "_, n_outputs = np.shape(y)\n",
    "\n",
    "non_bias_weights = np.zeros((n_features, n_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 39480,
     "status": "ok",
     "timestamp": 1596983947504,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "9UX_0qJGGr2X",
    "outputId": "0df78a57-5df9-4a33-ad69-87848149879d"
   },
   "outputs": [],
   "source": [
    "non_bias_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 39459,
     "status": "ok",
     "timestamp": 1596983947505,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "Z_IqhLJQGhWw",
    "outputId": "cd870f03-8af8-4849-e3b3-d2564d398d9f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Removing bias term and training the network only with weights.\n",
    "trained_weights = train(X, y, non_bias_weights, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 116420,
     "status": "ok",
     "timestamp": 1596984024485,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "mCnfBDIzG1ck",
    "outputId": "b4eca0ee-84f9-4f3d-88df-8732366e48da"
   },
   "outputs": [],
   "source": [
    "generate_gifs(X, y, trained_weights, 'train', path='content/training_decision_boundary_with_non_bias_weights.gif', bias='off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r33FPGkUYCOf"
   },
   "source": [
    "![non_bias_weights](https://drive.google.com/uc?id=1_uHN5z-LLj0bpPmRJBBe8Z6UKoq63DK5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O_s2yYYZgWAQ"
   },
   "source": [
    "From the above gif, we can see that the decision boundary (or line equation) always passes through $0$ and is of the form: $\\text{const1} \\times x + \\text{const2} \\times y = 0$. What happens if we include the bias term while training the perceptron model? Let's see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 116414,
     "status": "ok",
     "timestamp": 1596984024487,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "JnQ74jVbH6hD"
   },
   "outputs": [],
   "source": [
    "# Adding column of ones to absorb bias b of the hyperplane into X\n",
    "bias_ones = np.ones((len(X), 1))\n",
    "X = np.hstack((X, bias_ones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 116409,
     "status": "ok",
     "timestamp": 1596984024488,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "_IZDNzaCE_wG"
   },
   "outputs": [],
   "source": [
    "# Initializing weights to zero\n",
    "_, n_features = np.shape(X)\n",
    "_, n_outputs = np.shape(y)\n",
    "\n",
    "weights_with_bias = np.zeros((n_features, n_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 116383,
     "status": "ok",
     "timestamp": 1596984024489,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "2ULPJrYXH-FH",
    "outputId": "dc9566f8-7150-41c2-fb91-1602e9fd06d0"
   },
   "outputs": [],
   "source": [
    "weights_with_bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 116345,
     "status": "ok",
     "timestamp": 1596984024490,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "wpLpgebnjTqv",
    "outputId": "d8e20456-7a27-4e74-e1d7-fb124c197538"
   },
   "outputs": [],
   "source": [
    "# Adding bias term and training the network only with weights.\n",
    "trained_weights = train(X, y, weights_with_bias, learning_rate=0.1, total_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 116336,
     "status": "ok",
     "timestamp": 1596984024491,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "c85doyklre90"
   },
   "outputs": [],
   "source": [
    "# Taking last 50 weights since creating gif files can take too much time\n",
    "if len(trained_weights) > 100:\n",
    "  last_50_trained_weights = trained_weights[len(trained_weights)-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 160626,
     "status": "ok",
     "timestamp": 1596984068809,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "j3OozbJhjqj8",
    "outputId": "54d477b9-7f48-4d5d-a79c-374c4d20f58c"
   },
   "outputs": [],
   "source": [
    "generate_gifs(X, y, last_50_trained_weights, 'train', path='content/training_decision_boundary_weights_with_bias.gif', bias='on')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_5i2N3qCYX6s"
   },
   "source": [
    "![weights_with_bias](https://drive.google.com/uc?id=1xe0vlF_6vgwShpxcoKw7a4W324PoQVgA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nfx4sab0JggJ"
   },
   "source": [
    "From the above gif, we can see that bias helps translate the decision boundary by representing pattern that don't necessarily pass through zero. In effect, a bias value lets you to shift the activation function by learning an appropriate threshold. One bias unit is always sufficient since it will affect each neuron differently based on its weight with each unit. Generally, to successfully learn an ML model, it almost always helpful to assign bias to every non-input since without bias, weights would have thresholds that will always be zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rHr757uTkc0f"
   },
   "source": [
    "## Partially separable dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hv-cSdimww8U"
   },
   "source": [
    "Let's see how the perceptron learns the decision boundary on a partially separable dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 160619,
     "status": "ok",
     "timestamp": 1596984068812,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "6MnB0OODkiNR"
   },
   "outputs": [],
   "source": [
    "# Initializing weights to zero\n",
    "_, n_features = np.shape(X)\n",
    "_, n_outputs = np.shape(y)\n",
    "\n",
    "weights_with_bias = np.zeros((n_features, n_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 160597,
     "status": "ok",
     "timestamp": 1596984068814,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "3TXc0C8XlQdM",
    "outputId": "c043af39-be91-481a-f5cd-30992c6d0c27"
   },
   "outputs": [],
   "source": [
    "weights_with_bias.shape, X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 160588,
     "status": "ok",
     "timestamp": 1596984068815,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "p8yk-aUalccj"
   },
   "outputs": [],
   "source": [
    "# Collecting all indexes with class label = 1. Ramdomly sampling 5 indexes\n",
    "# and setting class labels = -1\n",
    "np.random.seed(10)\n",
    "idxs_class_labels_one = np.argwhere(y == 1)[:, 0]\n",
    "idxs_class_labels_one = random.sample(idxs_class_labels_one.tolist(), 5)\n",
    "y[idxs_class_labels_one] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 160567,
     "status": "ok",
     "timestamp": 1596984068818,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "kdaXbVWdtvuf",
    "outputId": "28504862-575a-44a3-983d-430f26cfecc8"
   },
   "outputs": [],
   "source": [
    "# Adding bias term and training the network only with weights.\n",
    "trained_weights = train(X, y, weights_with_bias, learning_rate=0.1, total_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 160558,
     "status": "ok",
     "timestamp": 1596984068820,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "3MB6JGjgt_dO"
   },
   "outputs": [],
   "source": [
    "# Taking last 50 weights since creating gif files can take too much time\n",
    "if len(trained_weights) > 100:\n",
    "  last_50_trained_weights = trained_weights[len(trained_weights)-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 205335,
     "status": "ok",
     "timestamp": 1596984113623,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "pLDAkrWjuEgC",
    "outputId": "ecee508b-6ec5-43aa-a166-604d0c60e15d"
   },
   "outputs": [],
   "source": [
    "generate_gifs(X, y, last_50_trained_weights, 'train', path='content/training_decision_boundary_partially_separable_dataset.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RWyZvmkYlEkW"
   },
   "source": [
    "![perceptron_partially_separable](https://drive.google.com/uc?id=1CCtJwO8ltKA_u1dcjJ71f91YHvhn6HyA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t05LtbdHJmxX"
   },
   "source": [
    "# Perceptron learning and the XOR problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 205330,
     "status": "ok",
     "timestamp": 1596984113629,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "QFv4hVjlJrz_"
   },
   "outputs": [],
   "source": [
    "# Setting the seed to ensure reproducibility of experiments\n",
    "np.random.seed(10)\n",
    "\n",
    "# Set the input data\n",
    "X = np.array([[0, 0], [0, 1],\n",
    "              [1, 0], [1, 1]])\n",
    "\n",
    "# Set the labels, the correct results for the xor operation\n",
    "y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "# Adding column of ones to absorb bias b of the hyperplane into X\n",
    "bias_ones = np.ones((len(X), 1))\n",
    "X = np.hstack((X, bias_ones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 205322,
     "status": "ok",
     "timestamp": 1596984113631,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "ztRKcmr8IPej"
   },
   "outputs": [],
   "source": [
    "# Initializing weights from uniform distribution\n",
    "np.random.seed(312)\n",
    "n_samples, n_features = np.shape(X)\n",
    "_, n_outputs = np.shape(y)\n",
    "\n",
    "limit = 1 / math.sqrt(n_features)\n",
    "weights = np.random.uniform(-limit, limit, (n_features, n_outputs))\n",
    "weights[-1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 205299,
     "status": "ok",
     "timestamp": 1596984113634,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "D8Hyenjim9p2",
    "outputId": "b3645aee-53fe-431e-85e4-5b0bc2929c09"
   },
   "outputs": [],
   "source": [
    "# Train the network with the above weights\n",
    "trained_weights = train(X, y, weights, learning_rate=0.1, total_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 223985,
     "status": "ok",
     "timestamp": 1596984132345,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "SWP7rJFf0UXO",
    "outputId": "5696ab8c-bd6d-4f0c-e216-142a5c2fbd6f"
   },
   "outputs": [],
   "source": [
    "generate_gifs(X, y, trained_weights, 'train', path='content/xor_training_decision_boundary.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C164QT0NYkxj"
   },
   "source": [
    "![xor_training](https://drive.google.com/uc?id=15oVhRH7XCnb1dPf-tCypfF4G2yvuD6Gv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v_3xqMQnnB2S"
   },
   "source": [
    "By training the perceptron model for 10 epochs we can clearly see from the gif above, that at a time, atleast 2 to atmost 3 of the points are missclassified. \n",
    "\n",
    "This characteristic persists even if we train the perceptron model for higher number of epochs. The perceptron is unable to classify all the points correctly. Theoretically, the perceptron is unable to converge on a XOR dataset. Why do you think this is the case? The reason is because the classes in XOR are not linearly separable."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ZQQfFFOrqST3"
   ],
   "name": "LinearPerceptron_draft4.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
